{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNEy6zyVgK7ujec1xvV2wBx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HectorDelgadoJ/Laboratorio-7/blob/main/Laboratorio7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Laboratorio 7\n",
        "\n",
        "En esta práctica, implementaremos y validaremos el clasificador K-Nearest Neighbors (KNN), un algoritmo de clasificación basado en la proximidad de puntos en el espacio de características. Se elegirá el valor óptimo de K mediante la partición de Hold-Out (70/30 estratificado) y se evaluará el desempeño del clasificador utilizando tres métodos de validación: Hold-Out estratificado, 10-Fold Cross-Validation estratificado y Leave-One-Out. Al final, mediremos la precisión (accuracy) y analizaremos la matriz de confusión para evaluar la calidad del modelo en tres datasets distintos."
      ],
      "metadata": {
        "id": "NSKN-uhwPpyF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## * Paso 1: Importar bibliotecas y cargar los datasets\n",
        "\n"
      ],
      "metadata": {
        "id": "puvk5lKpQ0hd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris, load_wine, load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, LeaveOneOut\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n"
      ],
      "metadata": {
        "id": "96CbcpcDQ-1G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## * Paso 2: Cargar los datos y explorar"
      ],
      "metadata": {
        "id": "krvyXySSRBcj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datasets = {\n",
        "    'Iris': load_iris(),\n",
        "    'Wine': load_wine(),\n",
        "    'Breast Cancer': load_breast_cancer()\n",
        "}\n",
        "\n",
        "# Verificamos los primeros datos de cada dataset\n",
        "for name, dataset in datasets.items():\n",
        "    print(f\"{name} dataset shape: {dataset.data.shape}\")\n",
        "    print(f\"Features: {dataset.feature_names}\")\n",
        "    print(f\"Classes: {dataset.target_names}\\n\")\n"
      ],
      "metadata": {
        "id": "egGYj6MkRGfd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## * Paso 3: Implementar el modelo KNN y seleccionar el valor de K"
      ],
      "metadata": {
        "id": "WwTqUmPeRKzj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def choose_best_k(X, y, max_k=20):\n",
        "    accuracies = []\n",
        "    for k in range(1, max_k + 1):\n",
        "        knn = KNeighborsClassifier(n_neighbors=k)\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
        "        knn.fit(X_train, y_train)\n",
        "        y_pred = knn.predict(X_test)\n",
        "        accuracies.append(accuracy_score(y_test, y_pred))\n",
        "    best_k = accuracies.index(max(accuracies)) + 1\n",
        "    print(f\"Best K: {best_k} with Accuracy: {max(accuracies):.2f}\")\n",
        "    return best_k\n"
      ],
      "metadata": {
        "id": "LnmaNqVHRJza"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## * Paso 4: Validar con los métodos de validación"
      ],
      "metadata": {
        "id": "0PREb0sARQj5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def validate_knn(X, y, k):\n",
        "    knn = KNeighborsClassifier(n_neighbors=k)\n",
        "\n",
        "    # Hold-Out 70/30\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
        "    knn.fit(X_train, y_train)\n",
        "    y_pred = knn.predict(X_test)\n",
        "    print(\"Hold-Out Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "\n",
        "    # 10-Fold Cross-Validation\n",
        "    skf = StratifiedKFold(n_splits=10)\n",
        "    cv_scores = cross_val_score(knn, X, y, cv=skf)\n",
        "    print(\"10-Fold Cross-Validation Accuracy:\", np.mean(cv_scores))\n",
        "\n",
        "    # Leave-One-Out\n",
        "    loo = LeaveOneOut()\n",
        "    loo_scores = cross_val_score(knn, X, y, cv=loo)\n",
        "    print(\"Leave-One-Out Accuracy:\", np.mean(loo_scores))\n"
      ],
      "metadata": {
        "id": "ieW7dWaFRUS9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *Paso 5: Ejecutar el código completo"
      ],
      "metadata": {
        "id": "xg_ml9p8RZWK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for name, dataset in datasets.items():\n",
        "    print(f\"\\n--- Validating on {name} dataset ---\")\n",
        "    X, y = dataset.data, dataset.target\n",
        "    best_k = choose_best_k(X, y)\n",
        "    validate_knn(X, y, best_k)\n"
      ],
      "metadata": {
        "id": "1sF3cpeMRc4d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "El código completo qudaria:"
      ],
      "metadata": {
        "id": "77Khsn51Rgzl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris, load_wine, load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, LeaveOneOut\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "# Datasets\n",
        "datasets = {\n",
        "    'Iris': load_iris(),\n",
        "    'Wine': load_wine(),\n",
        "    'Breast Cancer': load_breast_cancer()\n",
        "}\n",
        "\n",
        "# Function to choose the best K\n",
        "def choose_best_k(X, y, max_k=20):\n",
        "    accuracies = []\n",
        "    for k in range(1, max_k + 1):\n",
        "        knn = KNeighborsClassifier(n_neighbors=k)\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
        "        knn.fit(X_train, y_train)\n",
        "        y_pred = knn.predict(X_test)\n",
        "        accuracies.append(accuracy_score(y_test, y_pred))\n",
        "    best_k = accuracies.index(max(accuracies)) + 1\n",
        "    print(f\"Best K: {best_k} with Accuracy: {max(accuracies):.2f}\")\n",
        "    return best_k\n",
        "\n",
        "# Function to validate KNN with different validation methods\n",
        "def validate_knn(X, y, k):\n",
        "    knn = KNeighborsClassifier(n_neighbors=k)\n",
        "\n",
        "    # Hold-Out 70/30\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
        "    knn.fit(X_train, y_train)\n",
        "    y_pred = knn.predict(X_test)\n",
        "    print(\"Hold-Out Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "\n",
        "    # 10-Fold Cross-Validation\n",
        "    skf = StratifiedKFold(n_splits=10)\n",
        "    cv_scores = cross_val_score(knn, X, y, cv=skf)\n",
        "    print(\"10-Fold Cross-Validation Accuracy:\", np.mean(cv_scores))\n",
        "\n",
        "    # Leave-One-Out\n",
        "    loo = LeaveOneOut()\n",
        "    loo_scores = cross_val_score(knn, X, y, cv=loo)\n",
        "    print(\"Leave-One-Out Accuracy:\", np.mean(loo_scores))\n",
        "\n",
        "# Running the full validation on each dataset\n",
        "for name, dataset in datasets.items():\n",
        "    print(f\"\\n--- Validating on {name} dataset ---\")\n",
        "    X, y = dataset.data, dataset.target\n",
        "    best_k = choose_best_k(X, y)\n",
        "    validate_knn(X, y, best_k)\n"
      ],
      "metadata": {
        "id": "RouRyNMORkf7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}